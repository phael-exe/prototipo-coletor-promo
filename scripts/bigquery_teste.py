import sys
import os
import logging

# Configura√ß√£o de logs
logging.basicConfig(
    level=logging.INFO, 
    format='%(asctime)s - %(levelname)s - %(message)s'
)

# Adiciona o diret√≥rio raiz ao PYTHONPATH
current_dir = os.path.dirname(os.path.abspath(__file__))
root_dir = os.path.dirname(current_dir)
sys.path.append(root_dir)

# Configura a vari√°vel de ambiente para as credenciais
# Procura por qualquer arquivo .json em secrets/ se GOOGLE_APPLICATION_CREDENTIALS n√£o estiver setada
if not os.environ.get("GOOGLE_APPLICATION_CREDENTIALS"):
    secrets_dir = os.path.join(root_dir, "secrets")
    if os.path.exists(secrets_dir):
        json_files = [f for f in os.listdir(secrets_dir) if f.endswith('.json')]
        if json_files:
            # Usa o primeiro arquivo JSON encontrado
            credentials_file = os.path.join(secrets_dir, json_files[0])
            os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = credentials_file
            print(f"‚úÖ Credenciais GCP encontradas: {json_files[0]}")
        else:
            print("‚ùå Nenhum arquivo .json encontrado em secrets/")
    else:
        print("‚ùå Diret√≥rio secrets/ n√£o encontrado")

from app.services.crawler import CrawlerService
from app.services.bigquery import BigQueryService

# Configura√ß√£o das fontes de busca
SOURCES = [
    "monitor gamer 144hz",
    "iphone 16",  # Usando 16 pois 17 pode n√£o existir ainda
    "ps5",
]

# Configura√ß√£o de coleta
LIMIT_PER_SOURCE = 100      # M√°ximo de produtos por fonte
MAX_PAGES_PER_SOURCE = 3    # M√°ximo de p√°ginas por fonte
DELAY_BETWEEN_REQUESTS = 1.5  # Delay entre requisi√ß√µes (rate limit)


def main():
    print("\n" + "="*70)
    print("üóÑÔ∏è  COLETA MULTI-FONTE COM PAGINA√á√ÉO + BIGQUERY")
    print("="*70 + "\n")

    # 1. Instancia os servi√ßos
    try:
        crawler = CrawlerService()
        print(f"‚úÖ Crawler instanciado (execution_id: {crawler.execution_id})")
        
        bq = BigQueryService()
        print(f"‚úÖ BigQuery conectado: {bq.table_id}")
    except Exception as e:
        print(f"‚ùå Erro ao iniciar servi√ßos: {e}")
        import traceback
        traceback.print_exc()
        return

    # 2. Exibe configura√ß√£o
    print(f"\nüìã CONFIGURA√á√ÉO:")
    print(f"   Fontes: {SOURCES}")
    print(f"   Limite por fonte: {LIMIT_PER_SOURCE}")
    print(f"   M√°x. p√°ginas por fonte: {MAX_PAGES_PER_SOURCE}")
    print(f"   Delay entre requisi√ß√µes: {DELAY_BETWEEN_REQUESTS}s")
    print()

    # 3. Coleta de m√∫ltiplas fontes com pagina√ß√£o
    print("="*70)
    print("üîç INICIANDO COLETA")
    print("="*70 + "\n")
    
    try:
        results = crawler.fetch_from_sources(
            sources=SOURCES,
            limit_per_source=LIMIT_PER_SOURCE,
            max_pages_per_source=MAX_PAGES_PER_SOURCE,
            delay_between_requests=DELAY_BETWEEN_REQUESTS
        )
    except Exception as e:
        print(f"‚ùå Erro na coleta: {e}")
        import traceback
        traceback.print_exc()
        return

    # 4. Resumo da coleta por fonte
    print("\n" + "="*70)
    print("üìä RESUMO DA COLETA POR FONTE")
    print("="*70)
    
    all_products = []
    for source, products in results.items():
        all_products.extend(products)
        em_promo = sum(1 for p in products if p.has_discount)
        print(f"\nüì¶ {source}")
        print(f"   Produtos coletados: {len(products)}")
        print(f"   Em promo√ß√£o: {em_promo}")
        if products:
            avg_price = sum(p.price for p in products) / len(products)
            print(f"   Pre√ßo m√©dio: R$ {avg_price:.2f}")
    
    print(f"\nüéØ TOTAL COLETADO: {len(all_products)} produtos")
    print(f"   P√°ginas requisitadas: {crawler.stats['pages_fetched']}")

    # 5. Insere no BigQuery
    print("\n" + "="*70)
    print("üíæ INSERINDO NO BIGQUERY")
    print("="*70 + "\n")
    
    try:
        result = bq.insert_products(all_products)
        print(f"üìä RESULTADO DA INSER√á√ÉO:")
        print(f"   ‚úÖ Inseridos:   {result['inserted']}")
        print(f"   ‚è≠Ô∏è  Duplicados:  {result['duplicates']}")
        print(f"   ‚ùå Erros:       {result['errors']}")
    except Exception as e:
        print(f"‚ùå Erro na inser√ß√£o: {e}")
        import traceback
        traceback.print_exc()
        return

    # 6. Estat√≠sticas finais do BigQuery
    print("\n" + "="*70)
    print("üìà ESTAT√çSTICAS DO BIGQUERY")
    print("="*70)
    
    try:
        stats = bq.get_stats()
        if stats:
            print(f"\n   Total de produtos:    {stats.get('total_products', 0)}")
            print(f"   Itens √∫nicos:         {stats.get('unique_items', 0)}")
            print(f"   Total de execu√ß√µes:   {stats.get('total_executions', 0)}")
            print(f"   Produtos em promo√ß√£o: {stats.get('products_on_sale', 0)}")
            print(f"   Pre√ßo m√©dio geral:    R$ {stats.get('avg_price', 0):.2f}")
    except Exception as e:
        print(f"‚ö†Ô∏è  Erro ao buscar stats: {e}")

    print("\n" + "="*70)
    print("‚úÖ COLETA FINALIZADA!")
    print("="*70)
    print(f"\nüîó Verifique no console:")
    print(f"   https://console.cloud.google.com/bigquery?project=promozone-ml")

if __name__ == "__main__":
    main()
